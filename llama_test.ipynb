{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaping/anaconda3/envs/llama2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from the 'llama3' directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Specify the directory where the model is saved\n",
    "load_directory = \"llama3\"\n",
    "\n",
    "# Load the tokenizer and model in half precision\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_directory)\n",
    "\n",
    "# Use eos_token as the pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(load_directory, torch_dtype=torch.float16).to('cuda')\n",
    "\n",
    "# Ensure pad_token is set correctly\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"Model loaded successfully from the 'llama3' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 2 meters directly in front of you and a table 5 meters directly in front of you.\n",
      "    ### Drone Action (steps only, avoid the closest obstacle first, move forward and avoid moving backward):\n",
      "     - Move 0.5 meters forward (avoid the chair)\n",
      "     - Move 0.5 meters forward (move past the chair)\n",
      "     - Move 0.5 meters forward (avoid the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "     - Move 0.25 meters forward (move past the table)\n",
      "    ### Drone State (distance to the opposite side, distance to the obstacle, position\n"
     ]
    }
   ],
   "source": [
    "# # Set device: GPU if available, otherwise CPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Move model to the selected device\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Define the prompt template for drone interaction (focused on steps only, no backward movement)\n",
    "# def get_drone_prompt(instruction, environment, obstacle):\n",
    "#     prompt_template = \"\"\"\n",
    "#     ### Drone Instruction: {instruction}\n",
    "#     ### Environment: {environment_description}\n",
    "#     ### Obstacle Detected: {obstacle_type}\n",
    "#     ### Drone Action (steps only, avoid the closest obstacle first, move forward and avoid moving backward):\n",
    "#     \"\"\"\n",
    "#     return prompt_template.format(\n",
    "#         instruction=instruction,\n",
    "#         environment_description=environment,\n",
    "#         obstacle_type=obstacle\n",
    "#     )\n",
    "\n",
    "# # Example scenario: the drone is flying in a room with obstacles\n",
    "# instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "# environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "# obstacle_type = \"There is a chair 2 meters directly in front of you and a table 5 meters directly in front of you.\"\n",
    "\n",
    "# # Generate the prompt\n",
    "# formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type)\n",
    "\n",
    "# # Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "# inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# # Ensure model is in evaluation mode and run inference\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.generate(\n",
    "#         inputs,\n",
    "#         max_length=256,  # Adjust the max token limit as needed\n",
    "#         temperature=0.7,  # Adjust temperature for more deterministic or creative output\n",
    "#         top_p=1.0,\n",
    "#         top_k=0,  # Disable top-k filtering by setting top_k to 0\n",
    "#         repetition_penalty=1.0,\n",
    "#         early_stopping=True,\n",
    "#         pad_token_id=tokenizer.eos_token_id  # Set pad token ID to avoid warnings\n",
    "#     )\n",
    "\n",
    "# # Decode the generated output back to text\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# # Display the drone's action based on the generated response (steps only)\n",
    "# print(\"Drone's response to obstacle (steps only):\")\n",
    "# print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 3 meters directly in front of you.\n",
      "    ### Target Location: Opposite side of the room (15 meters away).\n",
      "    ### Drone Action: \n",
      "    Navigate towards the target using the following step-by-step instructions. \n",
      "    - Avoid all obstacles in the path by side stepping\n",
      "    - Move forward to reach the target location without moving backward\n",
      "    - Be concise in direction changes (e.g., turn left/right 90 degrees)\n",
      "    - Stop and side step if the obstacle is 1 meter directly in front of you\n",
      "    \n",
      "    Follow these steps:\n",
      "     1. Turn right 45 degrees to move around the chair.\n",
      "     2. Side step 0.5 meters to maintain distance from the chair.\n",
      "     3. Move forward 4 meters.\n",
      "     4. Turn left 135 degrees to align with the target direction.\n",
      "     5. Continue moving forward until reaching the target location.\n",
      "\n",
      "    Here's how your drone will execute this instruction:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "class Drone:\n",
      "    def __init__(self, x=0, y=0):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "        self.obstacles = {'chair': [10, 7]} # assuming we have an\n"
     ]
    }
   ],
   "source": [
    "# current best\n",
    "\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Target Location: {target_location}\n",
    "    ### Drone Action: \n",
    "    Navigate towards the target using the following step-by-step instructions. \n",
    "    - Avoid all obstacles in the path by side stepping\n",
    "    - Move forward to reach the target location without moving backward\n",
    "    - Be concise in direction changes (e.g., turn left/right 90 degrees)\n",
    "    - Stop and side step if the obstacle is 1 meter directly in front of you\n",
    "    \n",
    "    Follow these steps:\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 3 meters directly in front of you.\"\n",
    "target_location = \"Opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=300,  # Increase the max token limit for a longer response\n",
    "        temperature=0.4,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.95,       # Adjust to a broader probability range\n",
    "        top_k=50,         # Consider more tokens for diversity in navigation\n",
    "        repetition_penalty=1.15,  # Slight penalty to avoid repetitive text\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\n",
      "    ### Target Location: Opposite side of the room (15 meters away).\n",
      "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid any obstacles, move forward when there is no obstacle in, clear and concise, focus on avoiding obstacles and moving forward):\n",
      "     - Move forward 5 meters to create space between me and the chair.\n",
      "     - Sidestep left by 2 meters to avoid the chair.\n",
      "     - Move forward 4 meters to approach the table.\n",
      "     - Sidestep right by 1 meter to avoid the table.\n",
      "     - Move forward 6 meters to reach the middle of the room.\n",
      "     - Continue moving forward until I reach the opposite side of the room.\n",
      "\n",
      "### Python Code:\n",
      "```python\n",
      "import math\n",
      "\n",
      "# Define the drone's initial position\n",
      "drone_position = [0, 0]\n",
      "\n",
      "# Define the target location (opposite side\n"
     ]
    }
   ],
   "source": [
    "# still testing\n",
    "\n",
    "# Set device: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the prompt template for drone interaction (focused on steps only, no backward movement)\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Target Location: {target_location}\n",
    "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid any obstacles, move forward when there is no obstacle in, clear and concise, focus on avoiding obstacles and moving forward):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\"\n",
    "target_location = \"Opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.5,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.9,        # Narrow down the probability range\n",
    "        top_k=40,         # Choose from the top 40 most likely next tokens\n",
    "        repetition_penalty=1.1,  # Slight penalty to avoid repetitive text\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\n",
      "    ### Target Location: Opposite side of the room (15 meters away).\n",
      "    ### Drone Action: \n",
      "    Navigate towards the target using the following step-by-step instructions. \n",
      "    - Focus on sidestepping obstacles.\n",
      "    - Move forward when clear, and turn as needed to avoid obstacles.\n",
      "    - Be concise in direction changes (e.g., turn left/right 90 degrees).\n",
      "    \n",
      "    Follow these steps:\n",
      "     1. Move forward until you're 2 meters from the chair.\n",
      "     2. Turn right 45 degrees to move around the chair.\n",
      "     3. Move forward until you're 2 meters past the chair.\n",
      "     4. Turn right 90 degrees to change course and avoid the table.\n",
      "     5. Move forward until you're 8 meters past the table.\n",
      "     6. Turn left 90 degrees to adjust your trajectory.\n",
      "     7. Continue moving forward until you\n"
     ]
    }
   ],
   "source": [
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Target Location: {target_location}\n",
    "    ### Drone Action: \n",
    "    Navigate towards the target using the following step-by-step instructions. \n",
    "    - Focus on sidestepping obstacles.\n",
    "    - Move forward when clear, and turn as needed to avoid obstacles.\n",
    "    - Be concise in direction changes (e.g., turn left/right 90 degrees).\n",
    "    \n",
    "    Follow these steps:\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\"\n",
    "target_location = \"Opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.5,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.9,        # Narrow down the probability range\n",
    "        top_k=40,         # Choose from the top 40 most likely next tokens\n",
    "        repetition_penalty=1.1,  # Slight penalty to avoid repetitive text\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\n",
      "    ### Target Location: Opposite side of the room (15 meters away).\n",
      "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid obstacles, and move forward in small steps):\n",
      "     - Move forward by 1 meter\n",
      "     - Check if there's an obstacle ahead\n",
      "     - If there's an obstacle, calculate its distance from the drone\n",
      "     - If the obstacle is closer than the target, sidestep to the left/right by 0.5 meters\n",
      "     - Repeat the process until reaching the target\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "# Define the environment dimensions\n",
      "ROOM_WIDTH = 15\n",
      "ROOM_HEIGHT = 15\n",
      "\n",
      "# Define the obstacle positions\n",
      "CHAIR_X = 7\n",
      "CHAIR_Y = 10\n",
      "TABLE_X = 9\n",
      "TABLE_Y = 12\n",
      "\n",
      "# Define the target position\n",
      "TARGET_X = ROOM_WIDTH - 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Define the prompt template for drone interaction (focused on steps only, no backward movement)\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Target Location: {target_location}\n",
    "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid obstacles, and move forward in small steps):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\"\n",
    "target_location = \"Opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.5,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.9,        # Narrow down the probability range\n",
    "        top_k=40,         # Choose from the top 40 most likely next tokens\n",
    "        repetition_penalty=1.1,  # Slight penalty to avoid repetitive text\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's new position after forward by 2 meters: (x: 2.00, y: 0.00)\n",
      "Drone's new position after sidestep left by 1 meters: (x: 2.00, y: -1.00)\n",
      "Drone's new position after forward by 2 meters: (x: 4.00, y: -1.00)\n",
      "Drone's new position after sidestep right by 0.5 meters: (x: 4.00, y: -0.50)\n",
      "Drone's new position after forward by 10 meters: (x: 14.00, y: -0.50)\n",
      "Final drone position: (x: 14.00, y: -0.50)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Define the initial position and orientation of the drone\n",
    "drone_x = 0\n",
    "drone_y = 0\n",
    "drone_orientation = 0  # Assuming 0 degrees is facing \"up\" or forward\n",
    "\n",
    "# Function to update the drone's position based on a step command\n",
    "def update_drone_position(drone_x, drone_y, drone_orientation, movement_type, distance):\n",
    "    if movement_type == \"forward\":\n",
    "        # Move in the direction the drone is facing\n",
    "        drone_x += distance * math.cos(math.radians(drone_orientation))\n",
    "        drone_y += distance * math.sin(math.radians(drone_orientation))\n",
    "    elif movement_type == \"sidestep left\":\n",
    "        # Move perpendicular to the current direction (left side is -90 degrees)\n",
    "        drone_x += distance * math.cos(math.radians(drone_orientation - 90))\n",
    "        drone_y += distance * math.sin(math.radians(drone_orientation - 90))\n",
    "    elif movement_type == \"sidestep right\":\n",
    "        # Move perpendicular to the current direction (right side is +90 degrees)\n",
    "        drone_x += distance * math.cos(math.radians(drone_orientation + 90))\n",
    "        drone_y += distance * math.sin(math.radians(drone_orientation + 90))\n",
    "    \n",
    "    return drone_x, drone_y\n",
    "\n",
    "# Example generated drone instructions\n",
    "instructions = [\n",
    "    (\"forward\", 2),  # Move 2 meters forward\n",
    "    (\"sidestep left\", 1),  # Sidestep left by 1 meter\n",
    "    (\"forward\", 2),  # Move forward again by 2 meters\n",
    "    (\"sidestep right\", 0.5),  # Sidestep right by 0.5 meters\n",
    "    (\"forward\", 10)  # Move forward until reaching the opposite side\n",
    "]\n",
    "\n",
    "# Simulate the drone's movement step by step\n",
    "for step in instructions:\n",
    "    movement_type, distance = step\n",
    "    drone_x, drone_y = update_drone_position(drone_x, drone_y, drone_orientation, movement_type, distance)\n",
    "    print(f\"Drone's new position after {movement_type} by {distance} meters: (x: {drone_x:.2f}, y: {drone_y:.2f})\")\n",
    "\n",
    "# Final position\n",
    "print(f\"Final drone position: (x: {drone_x:.2f}, y: {drone_y:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\n",
      "    ### Target Location: Opposite side of the room (15 meters away).\n",
      "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid obstacles, and move forward in small steps):\n",
      "     - Move forward by 1 meter.\n",
      "     - Detect obstacles within 2 meters radius.\n",
      "     - If an obstacle is detected:\n",
      "       - Calculate distance to each obstacle.\n",
      "       - Choose the closest obstacle and calculate its angle relative to your current position.\n",
      "       - Turn left or right based on the calculated angle.\n",
      "       - Repeat this process until the obstacle is avoided.\n",
      "\n",
      "### Code\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "class Drone:\n",
      "    def __init__(self, x=0, y=0):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "        self.target_x = 15\n",
      "        self.target_y = 15\n",
      "        self.obstacles = []\n",
      "\n",
      "    def navigate(self):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template for drone interaction (focused on steps only, no backward movement)\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Target Location: {target_location}\n",
    "    ### Drone Action (navigate towards the target, avoid the closest obstacle first, use sidesteps to avoid obstacles, and move forward in small steps):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 3 meters directly in front of you and a table 4 meters in front of you.\"\n",
    "target_location = \"Opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.5,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.9,        # Narrow down the probability range\n",
    "        top_k=40,         # Choose from the top 40 most likely next tokens\n",
    "        repetition_penalty=1.1,  # Slight penalty to avoid repetitive text\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaping/anaconda3/envs/llama2/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 2 meters directly in front of you and a table 5 meters directly in front of you.\n",
      "    ### Drone Action (steps only, avoid the closest obstacle first, move forward and avoid moving backward):\n",
      "     - Move forward 5 meters.\n",
      "     - Turn 90 degrees to the left and move forward 5 meters.\n",
      "     - Turn 90 degrees to the left and move forward 5 meters.\n",
      "     - Turn 90 degrees to the left and move forward 1 meter.\n",
      "    ### Question: What is the drone's final position and orientation after executing these instructions?\n",
      "\n",
      "# Drone Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "# Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "# Obstacle Detected: There is a chair 2 meters directly in front of you and a table 5 meters directly in front of you.\n",
      "# Drone Action (steps only, avoid the closest obstacle first, move forward and avoid moving backward):\n",
      "#  - Move forward \n"
     ]
    }
   ],
   "source": [
    "# Set device: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the prompt template for drone interaction (focused on steps only, no backward movement)\n",
    "def get_drone_prompt(instruction, environment, obstacle):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Drone Action (steps only, avoid the closest obstacle first, move forward and avoid moving backward):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 2 meters directly in front of you and a table 5 meters directly in front of you.\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.7,  # Adjust temperature for more deterministic or creative output\n",
    "        top_p=1.0,\n",
    "        top_k=0,  # Disable top-k filtering by setting top_k to 0\n",
    "        repetition_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id  # Set pad token ID to avoid warnings\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response (steps only)\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response to obstacle (steps only):\n",
      "\n",
      "    ### Drone Instruction: Fly forward and avoid obstacles.\n",
      "    ### Environment: The room is 10x10 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 5 meters in front and a table 2 meters infront.\n",
      "    ### Drone Action (steps only):\n",
      "     1. Fly forward 3 meters.\n",
      "     2. Obstacle detected: chair 5 meters in front.\n",
      "     3. Obstacle detected: table 2 meters in front.\n",
      "     4. Fly forward 1 meter.\n",
      "     5. Obstacle detected: table 2 meters in front.\n",
      "     6. Fly forward 1.5 meters.\n",
      "     7. No obstacles detected.\n",
      "    ### Drone Action is: Return to base.\n",
      "\n",
      "The final answer is: Return to base.     ### Drone Instruction: Fly forward and avoid obstacles.\n",
      "    ### Environment: The room is 10x10 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle Detected: There is a chair 5 meters in front and a table 2 meters infront.\n",
      "    ### Drone Action (steps only):\n",
      "     1. Fly forward 3 meters.\n",
      "     2. Obstacle detected: chair 5 meters in front\n"
     ]
    }
   ],
   "source": [
    "# Set device: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the prompt template for drone interaction\n",
    "def get_drone_prompt(instruction, environment, obstacle):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Drone Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle Detected: {obstacle_type}\n",
    "    ### Drone Action (steps only):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly forward and avoid obstacles.\"\n",
    "environment_description = \"The room is 10x10 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"There is a chair 5 meters in front and a table 2 meters infront.\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=256,  # Adjust the max token limit as needed\n",
    "        temperature=0.7,  # Adjust temperature for more deterministic or creative output\n",
    "        top_p=1.0,\n",
    "        top_k=0,  # Disable top-k filtering by setting top_k to 0\n",
    "        repetition_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id  # Set pad token ID to avoid warnings\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's action based on the generated response\n",
    "print(\"Drone's response to obstacle (steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response (navigation steps only):\n",
      "\n",
      "    ### Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle: A chair is 2 meters in front, a table is 4 meters ahead, and other scattered items.\n",
      "    ### Target: The opposite side of the room (15 meters away).\n",
      "    ### Navigation Instructions (clear and concise, focus on avoiding obstacles and moving forward):\n",
      "     - Move forward 5 meters.\n",
      "     - Turn left 90 degrees.\n",
      "     - Move forward 3 meters.\n",
      "     - Turn right 90 degrees.\n",
      "     - Move forward 2 meters.\n",
      "     - Turn left 90 degrees.\n",
      "     - Move forward\n"
     ]
    }
   ],
   "source": [
    "# Define the refined prompt template for drone navigation (focused on concise and efficient steps)\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle: {obstacle_type}\n",
    "    ### Target: {target_location}\n",
    "    ### Navigation Instructions (clear and concise, focus on avoiding obstacles and moving forward):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"A chair is 2 meters in front, a table is 4 meters ahead, and other scattered items.\"\n",
    "target_location = \"The opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=150,  # Shorter max token limit to focus on efficiency\n",
    "        temperature=0.3,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.85,       # Lower value to focus on the top-ranked tokens\n",
    "        top_k=30,         # Fewer top choices for more direct actions\n",
    "        repetition_penalty=1.05,  # Mild repetition penalty to prevent redundancy\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's concise navigation instructions\n",
    "print(\"Drone's response (navigation steps only):\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drone's response (navigation steps only):\n",
      "\n",
      "    ### Instruction: Fly to the opposite side of the room and avoid all obstacles.\n",
      "    ### Environment: The room is 15x15 meters with several tables and chairs scattered around.\n",
      "    ### Obstacle: A chair is 2 meters in front, a table is 4 meters ahead, and other scattered items.\n",
      "    ### Target: The opposite side of the room (15 meters away).\n",
      "    ### Navigation Instructions (number the steps, focus on avoiding obstacles and moving forward efficiently):\n",
      "     - Step 1: Move straight for 5 meters while keeping an eye out for any objects that might be blocking your path. \n",
      "     - Step 2: If you see a chair or another obstacle within this distance, adjust your course slightly left or right by about one meter to go around it without touching anything. Otherwise, continue moving straight until you reach the end of step 3.\n",
      "     - Step 3: Once past the initial area where potential obstructions were present, move directly towards\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the refined prompt template for drone navigation (focused on concise and efficient steps)\n",
    "def get_drone_prompt(instruction, environment, obstacle, target):\n",
    "    prompt_template = \"\"\"\n",
    "    ### Instruction: {instruction}\n",
    "    ### Environment: {environment_description}\n",
    "    ### Obstacle: {obstacle_type}\n",
    "    ### Target: {target_location}\n",
    "    ### Navigation Instructions (number the steps, focus on avoiding obstacles and moving forward efficiently):\n",
    "    \"\"\"\n",
    "    return prompt_template.format(\n",
    "        instruction=instruction,\n",
    "        environment_description=environment,\n",
    "        obstacle_type=obstacle,\n",
    "        target_location=target\n",
    "    )\n",
    "\n",
    "# Example scenario: the drone is flying in a room with obstacles\n",
    "instruction = \"Fly to the opposite side of the room and avoid all obstacles.\"\n",
    "environment_description = \"The room is 15x15 meters with several tables and chairs scattered around.\"\n",
    "obstacle_type = \"A chair is 2 meters in front, a table is 4 meters ahead, and other scattered items.\"\n",
    "target_location = \"The opposite side of the room (15 meters away).\"\n",
    "\n",
    "# Generate the prompt\n",
    "formatted_prompt = get_drone_prompt(instruction, environment_description, obstacle_type, target_location)\n",
    "\n",
    "# Encode the prompt using the tokenizer and move it to the same device as the model\n",
    "inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Ensure model is in evaluation mode and run inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=200,  # Increased max token limit to allow complete response\n",
    "        temperature=0.2,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.9,        # Keep top_p to ensure variety but avoid outliers\n",
    "        top_k=40,         # Top 40 tokens to balance between variety and accuracy\n",
    "        repetition_penalty=1.2,  # Increase repetition penalty to avoid repeating unnecessary steps\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode the generated output back to text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the drone's concise navigation instructions\n",
    "print(\"Drone's response (navigation steps only):\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
